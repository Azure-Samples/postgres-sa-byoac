# 4.2 構造要素ベースのチャンク設定

構造要素ベースのチャンクは、RAG（リトリーバル・オーグメンテッド・ジェネレーション）やその他のAI駆動型ワークフローのために文書を準備する上で重要なステップです。これは、大きな文書をより小さく、意味的に意味のあるチャンクに分割することで、インデックス作成、検索、リトリーバルを改善します。Azure Document Intelligenceを使用することで、構造要素ベースのチャンクを設定し、下流プロセスのデータフローを最適化できます。

## Document Intelligenceにおけるチャンクとは？

**Azure AI Document Intelligence**では、「_チャンク_」とは、データの抽出、リトリーバル、検証を改善するために知的に分割された文書の構造化セグメントを指します。このプロセスは、**構造要素ベースのチャンク**として知られ、情報がページ番号のような任意の区分ではなく、その意味と文脈に基づいて論理的にグループ化されることを保証します。

### チャンクの仕組み

1. **意味の理解:** 文書を単一のテキストブロックとして扱うのではなく、AIモデルは見出し、段落、表、リストなどの主要なセクションを認識します。

1. **文脈の保持:** 文書の異なる部分間の関係を維持することで、チャンクはAIモデルが財務諸表、SOW、請求書をより正確に解釈するのを助けます。

1. **リトリーバル・オーグメンテッド・ジェネレーション（RAG）**モデルは、関連するチャンクを動的に取得し、AI駆動の文書検証、コンプライアンスチェック、財務データの調整を改善します。

### AI駆動のデータ検証におけるチャンクの重要性

- **高精度:** 構造化された文書のセグメンテーションは、AIの**主要な財務データの抽出と検証能力**を向上させます。  
- **より良い文脈的リトリーバル:** 請求書を**作業範囲書（SOW）**と比較する際、AIは**支払い条件に関連する特定の条項**を取得できます。  
- **最適化されたクエリパフォーマンス:** AI駆動の検索は、**より正確**で**文脈を考慮した**結果を返します。  

---

## Document Intelligenceにおけるチャンク戦略の定義

作業範囲書（SOW）や請求書を扱う際、効果的なチャンク戦略を定義することは、正確なデータ抽出、検証、クロスリファレンスを確保するために不可欠です。チャンクの構造は文書の種類によって異なります。**SOW**と**請求書**は異なる形式、目的、データ要件を持っているためです。

### 作業範囲記述書 (SOW) のチャンク化戦略

SOWは、契約上の義務、支払いマイルストーン、成果物、コンプライアンス条項を示す**長く構造化された文書**です。SOWのチャンク化戦略は、**文脈の整合性を保ちながら**関連セクションを簡単に取得できるようにすることに焦点を当てる必要があります。

#### SOWのための主要なチャンク化の考慮事項

1. **論理的なセクショニング:**  
    1. 見出し、副見出し、番号付き条項（例：**「作業範囲」**、**「支払い条件」**、**「マイルストーン」**）に基づいてチャンク化します。  
    1. AIが請求書を参照する際に関連する契約の詳細を取得できるようにします。  

1. **段落ベースの構造要素ベースのチャンク化:**  
    1. セクションを**意味的に意味のある段落**に分割して正確に取得します。  
    1. **RAGベースのAIモデル**が契約義務を理解するのに役立ちます。

1. **コンプライアンス条項の認識:**  
    1. 規制またはコンプライアンスの言語を特定し、別々にチャンク化して**自動法的チェック**を容易にします。

1. **成果物ベースのセグメンテーション:**  
    1. **支払い成果物**に基づいてチャンクを定義し、期待される請求書金額にリンクします。  

### 請求書のチャンク化戦略

請求書は、請求可能な項目、金額、期日を一覧表示するために設計された**構造化された表形式の文書**です。SOWとは異なり、請求書のチャンク化は表形式データの抽出、項目の正確性、およびSOWとの直接的な一致に焦点を当てる必要があります。

#### 請求書のための主要なチャンク化の考慮事項

1. **項目ごとのチャンク化:**  
    1. 各**項目（例：サービス、数量、金額、税金など）**は、正確なAI検証のために個別のチャンクとして扱われます。  
1. **テーブル対応のチャンク化:**  
    1. **表形式の構造**を保持して、AIが請求書の合計、税金、割引を正しく抽出および処理できるようにします。

1. **説明のための構造要素ベースのチャンク化:**  
    1. 請求書の説明は**プロジェクトの成果物を参照する可能性**があり、チャンク化によりAIがそれらを**SOWの成果物とクロスバリデート**できるようにします。  

1. **ベンダーと支払い条件のセグメンテーション:**  
    1. ベンダーの詳細、請求書の日付、および期日は別々にチャンク化して、**正確な支払いマイルストーンの検証**を確保します。  

### チャンク戦略の違い {/*examples*/}

| 項目                   | SOWチャンク戦略       | 請求書チャンク戦略         |
|-----------------------|----------------------|---------------------------|
| **ドキュメント構造**   | セクション付きの長文契約書 | 明細項目付きの構造化された表 |
| **チャンク方法**       | セクションと段落に基づくチャンク | 表に対応した明細項目のチャンク |
| **主要なチャンクの焦点** | マイルストーン、成果物、コンプライアンス条項 | 請求項目、支払い詳細 |
| **AIの取得目的**       | 契約上の義務とコンプライアンスの検証 | 請求可能な金額とSOWの期日を一致させる |

### 最適化されたチャンク戦略が重要な理由 {/*examples*/}

- **AIの精度を向上** – ドキュメントの検証が構造化された意味のあるチャンクに基づいて行われることを保証します。  
- **ドキュメント間の検証を強化** – AIモデルが**請求書をSOWに効率的に一致させる**ことを可能にします。  
- **コンプライアンスと監査可能性をサポート** – 必要なすべてのセクションが**適切にレビューされる**ことを保証します。  
- **取得強化生成（RAG）クエリを最適化** – AIが**正確な契約および請求書の詳細**を取得して分析できます。  

---

## Azure Document Intelligenceの活用 {/*examples*/}

Azure Document Intelligenceは、チャンクプロセスを自動化するためのツールと機能を提供します：

1. **事前トレーニング済みモデルの使用**:
   - 事前トレーニング済みモデルを適用して、構造化データを抽出し、ドキュメント内の論理的なセクションを特定します。このワークショップでは2つのモデルが使用されました：
    1. Document Intelligenceの**prebuilt-invoice**モデルは、請求書を処理するために使用されました。このモデルは、ベンダーの詳細、請求書の日付、合計金額など、請求書からの重要な情報を抽出するように設計されています。このモデルは、高度な機械学習技術を活用して請求書の処理を効率化し、手動のデータ入力を削減し、精度を向上させます。
    1. Document Intelligenceの**prebuilt-document**モデルは、Statement of Worksを処理するために使用されました。このモデルは、契約書、領収書、フォームなど、さまざまなドキュメントタイプから構造化データを抽出するように設計されています。このモデルは、関連情報を特定して抽出するために機械学習を使用し、効率的なドキュメント処理とデータ管理を可能にします。


1. **カスタムモデルの適用**:
    1. 事前構築されたモデルがドメイン固有のドキュメントに適さない場合、カスタムモデルを使用して、ユースケースに特有のセクションを識別することができます。
   [このガイドに従ってください](https://learn.microsoft.com/azure/ai-services/document-intelligence/how-to-guides/build-a-custom-model?view=doc-intel-4.0.0)

1. **セマンティックルールの設定**:
    1. セマンティックコンテンツに基づいてドキュメントをセグメント化するためのルールや条件を定義します。
    1. 例: 契約書を「関係者」、「義務」、「条件と条項」のセクションに分割します。

---

### Azure Database for PostgreSQLにチャンクを保存する

ドキュメントがセマンティックにチャンク化された後、結果のチャンクは効率的なクエリと取得のために**Azure Database for PostgreSQL**に保存されます:

1. **データ構造**:
    1. 各チャンクは、簡単に識別できるメタデータとともに個別のレコードとして保存されます。
    1. 例のスキーマ:

        ```sql
        CREATE TABLE sow_chunks (
            id BIGSERIAL PRIMARY KEY,
            sow_id BIGINT NOT NULL,
            heading, TEXT,
            content TEXT,
            page_number INT,
            FOREIGN KEY (sow_id) REFERENCES sows (id) ON DELETE CASCADE
        );
        ```

1. **メタデータ**:
    1. これには、効率的な取得のためにドキュメントID、チャンクシーケンス、セマンティックラベルなどのメタデータが含まれることがあります。

---

### 構造要素ベースのチャンク化の利点

1. **強化された取得**:
   1. 特定のドキュメントセクションの正確なクエリを可能にし、AI駆動の応答の精度を向上させます。

1. **最適化されたインデックス作成**:
    1. 大規模なドキュメントのインデックス作成の複雑さを、より小さく意味のあるセクションに焦点を当てることで軽減します。

1. **AIパフォーマンスの向上**:
    1. AIモデルがトークン制限内で動作することを保証し、切り捨てを避け、出力品質を向上させます。

---

## チャンクをPostgreSQLに書き込む

### Azure Database for PostgreSQLにおけるインテリジェントデータストレージ

チャンク化されたテキストデータは**Azure Database for PostgreSQL**に保存され、効率的なストレージと取得を保証します。

- **データの組織化**: ドキュメントはメタデータを伴った構造化フォーマットで保存されます。
- **スケーラビリティ**: 大量のデータを扱うために最適化されています。

---

### 4. Azure AI拡張機能を使用したベクトル埋め込みの生成

PostgreSQL用の**Azure AI拡張機能**は、セマンティック検索などの高度なAI機能を可能にします。

- **埋め込みストレージ**: ドキュメント埋め込み用のベクトル列を追加します。
- **埋め込み生成**: **Azure OpenAI** を使用して高次元ベクトル埋め込みを生成します。

SQLコマンドの例:

```sql
ALTER TABLE invoices ADD COLUMN embeddings VECTOR(1536);
ALTER TABLE sows ADD COLUMN embeddings VECTOR(1536);
```

---

### 挿入時にチャンクを挿入するためのAPIエンドポイント {/*examples*/}

アプリケーションでSOWをアップロードする際、ドキュメントワークフローは分析APIエンドポイント `/sows/` から始まります。このエンドポイントは、HTTP POSTを使用して、ベンダーの `vendor_id` とアップロードされるドキュメントファイルを渡して呼び出されます。

ドキュメントはDocument Intelligenceに渡され、ドキュメントからテキストを抽出します。

```python linenums="89" title="src/api/app/routers/sows.py"
  analysis_result = await doc_intelligence_service.extract_text_from_sow_document(document_data)
```

アプリケーションは、`src/api/app/services/azure_doc_intelligence_service.py` ファイル内にあるDocument Intelligenceを呼び出すサービスを実装しており、ここに `.extract_text_from_sow_document` メソッドがあります。このコードは、Document Intelligence内の `prebuild-document` モデルを使用してドキュメントからテキストを抽出します。

以下のセクションを展開すると、Document Intelligenceを呼び出してドキュメントからテキストを抽出し、テキストチャンクを生成するコードの特定のセクションを見ることができます。

???+ info "ドキュメントからテキストを抽出するためにDocument Intelligenceを呼び出す"

    ```python linenums="35" title="src/api/services/azure_doc_intelligence_service.py"
      async def extract_text_from_sow_document(self, document_data):
        """Extract text and structure using Azure AI Document Intelligence."""
        docClient = DocumentAnalysisClient(
            endpoint=self.docIntelligenceEndpoint,
            credential=self.credential
        )

        poller = await docClient.begin_analyze_document(
            model_id="prebuilt-document",
            document=document_data
        )

        result = await poller.result()

        analysis = DocumentAnalysisResult()
        analysis.extracted_text = []
        analysis.text_chunks = []
        
        known_headings = [
            "Project Scope", "Project Objectives", "Location", "Tasks", "Schedules",
            "Standards and Testing", "Payments", "Compliance", "Requirements", "Project Deliverables"
        ]

        for page in result.pages:
            page_text = " ".join([line.content for line in page.lines])
            analysis.extracted_text.append(page_text)

            current_heading = None
            for line in page.lines:
                text = line.content
                if self.__is_heading(text, known_headings): # Detect headings
                    current_heading = text
                    newTextChunk = TextChunk()
                    newTextChunk.heading = text
                    newTextChunk.content = ""
                    newTextChunk.page_number = page.page_number
                    analysis.text_chunks.append(newTextChunk)
                elif current_heading:
                    analysis.text_chunks[-1].content += " " + text

        await docClient.close()

        analysis.full_text = "\n".join(analysis.extracted_text)

        return analysis
    ```

`.extract_text_from_sow_document` メソッドは、ドキュメントからすべてのテキストチャンクを含む `.text_chunks` コレクションを含むオブジェクトを返します。その後、抽出されたチャンクをループしてデータベースに挿入します。

```python linenums="138" title="src/api/app/routers/sows.py"
for chunk in analysis_result.text_chunks:
    await conn.execute('''
        INSERT INTO sow_chunks (sow_id, heading, content, page_number) VALUES ($1, $2, $3, $4);
    ''', sow.id, chunk.heading, chunk.content, chunk.page_number)
```

データベースにロードされたテキストチャンクは、後でCopilotによってクエリされ、ドキュメントのテキスト内容に基づいた検索拡張生成（RAG）を実装するために利用可能になります。

## 追加学習リファレンス

- [ドキュメントインテリジェンス - ドキュメント処理モデル](https://learn.microsoft.com/azure/ai-services/document-intelligence/model-overview?view=doc-intel-4.0.0)

- [ドキュメントインテリジェンスでカスタムモデルを構築する](https://learn.microsoft.com/azure/ai-services/document-intelligence/how-to-guides/build-a-custom-model?view=doc-intel-4.0.0)

- [ドキュメントインテリジェンス - 検索強化生成](https://learn.microsoft.com/azure/ai-services/document-intelligence/concept/retrieval-augmented-generation?view=doc-intel-4.0.0)

!!! success "おめでとうございます。**構造要素ベースのチャンク化**の設定に関する主要な概念を学びました"
